{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MxkJoQBkUIHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "ZaTwK7ojXr2F",
        "outputId": "0b27a96d-d11a-43e8-ab4b-87c1f01896fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.13.0'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MXUkhkMfU4wq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv('../data/Churn_Modelling.csv')\n",
        "\n",
        "# when trainiug the model, we ignore irrelevant columns that don't have an impact in predictons (i.e. `customerId`, `surname`, etc)\n",
        "# also, the dependent variable (`exited`) is removed from the training data\n",
        "print(dataset.head(0))\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "colab_type": "code",
        "id": "VYP9cQTWbzuI",
        "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        0        1       2   3   4          5  6  7  8          9\n",
            "0     619   France  Female  42   2        0.0  1  1  1  101348.88\n",
            "1     608    Spain  Female  41   1   83807.86  1  0  1  112542.58\n",
            "2     502   France  Female  42   8   159660.8  3  1  0  113931.57\n",
            "3     699   France  Female  39   1        0.0  2  0  0   93826.63\n",
            "4     850    Spain  Female  43   2  125510.82  1  1  1    79084.1\n",
            "...   ...      ...     ...  ..  ..        ... .. .. ..        ...\n",
            "9995  771   France    Male  39   5        0.0  2  1  0   96270.64\n",
            "9996  516   France    Male  35  10   57369.61  1  1  1  101699.77\n",
            "9997  709   France  Female  36   7        0.0  1  0  1   42085.58\n",
            "9998  772  Germany    Male  42   3   75075.31  2  1  0   92888.52\n",
            "9999  792   France  Female  28   4  130142.79  1  1  0   38190.78\n",
            "\n",
            "[10000 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "# the independent variables\n",
        "print(pd.DataFrame(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "38vKGE6Nb2RR",
        "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0\n",
            "0     1\n",
            "1     0\n",
            "2     1\n",
            "3     0\n",
            "4     0\n",
            "...  ..\n",
            "9995  0\n",
            "9996  0\n",
            "9997  1\n",
            "9998  1\n",
            "9999  0\n",
            "\n",
            "[10000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "# the dependent variables\n",
        "print(pd.DataFrame(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data\n",
        "\n",
        "Label encidong is used to encode column values into a numerical representation. This way you can feed it into the NN for computation.\n",
        "\n",
        "A brief overview of `Label` and `One-hot` (strange name), can be found here: \n",
        "\n",
        "https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column\n",
        "\n",
        "This will replace `male`/`female` with `0` and `1` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PxVKWXxLbczC"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "colab_type": "code",
        "id": "-M1KboxFb6OO",
        "outputId": "e2b8c7e8-0cbc-4cdf-f4eb-7f0853a00b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "...  ..\n",
            "9995  1\n",
            "9996  1\n",
            "9997  0\n",
            "9998  1\n",
            "9999  0\n",
            "\n",
            "[10000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(pd.DataFrame(X[:, 2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column\n",
        "\n",
        "This will create three new columns (since we started from three distinct geographic regions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AMXC8-KMVirw"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "colab_type": "code",
        "id": "ZcxwEon-b8nV",
        "outputId": "23a98af4-5e33-4b26-c27b-f06e3c5d2baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        0    1    2\n",
            "0     1.0  0.0  0.0\n",
            "1     0.0  0.0  1.0\n",
            "2     1.0  0.0  0.0\n",
            "3     1.0  0.0  0.0\n",
            "4     0.0  0.0  1.0\n",
            "...   ...  ...  ...\n",
            "9995  1.0  0.0  0.0\n",
            "9996  1.0  0.0  0.0\n",
            "9997  1.0  0.0  0.0\n",
            "9998  0.0  1.0  0.0\n",
            "9999  1.0  0.0  0.0\n",
            "\n",
            "[10000 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# the newly added columns\n",
        "print(pd.DataFrame(X[:, :3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Z-TDt0Y_XEfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling\n",
        "\n",
        "Scale the input features of a dataset to ensure that they are on a similar scale. This process can have a significant impact on the training process and the performance of the NN\n",
        "\n",
        "For a more elaborate explanation see https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ViCrE00rV8Sk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Here, we store the scaler for later use during inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# in prod, we should probaly serialize sc & model state for later use during inference.\n",
        "pickle.dump(sc, open('scaler.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3dtrScHxXQox"
      },
      "outputs": [],
      "source": [
        "ann = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bppGycBXYCQr"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JneR0u0sYRTd"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Cn3x41RBYfvY"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fG3RrwDXZEaS"
      },
      "outputs": [],
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "nHZ-LKv_ZRb3",
        "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 801us/step - loss: 0.5489 - accuracy: 0.7797\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 829us/step - loss: 0.4926 - accuracy: 0.7960\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 805us/step - loss: 0.4751 - accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 839us/step - loss: 0.4578 - accuracy: 0.7984\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 805us/step - loss: 0.4438 - accuracy: 0.8065\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.4372 - accuracy: 0.8106\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.4327 - accuracy: 0.8104\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 810us/step - loss: 0.4295 - accuracy: 0.8114\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 815us/step - loss: 0.4266 - accuracy: 0.8129\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 806us/step - loss: 0.4239 - accuracy: 0.8158\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 852us/step - loss: 0.4217 - accuracy: 0.8169\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.4198 - accuracy: 0.8170\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 799us/step - loss: 0.4178 - accuracy: 0.8194\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.4159 - accuracy: 0.8202\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 789us/step - loss: 0.4148 - accuracy: 0.8199\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 790us/step - loss: 0.4136 - accuracy: 0.8194\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 802us/step - loss: 0.4123 - accuracy: 0.8207\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 798us/step - loss: 0.4115 - accuracy: 0.8219\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 789us/step - loss: 0.4105 - accuracy: 0.8227\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 803us/step - loss: 0.4094 - accuracy: 0.8231\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 798us/step - loss: 0.4087 - accuracy: 0.8241\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 829us/step - loss: 0.4072 - accuracy: 0.8249\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 792us/step - loss: 0.4061 - accuracy: 0.8261\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.4040 - accuracy: 0.8274\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 791us/step - loss: 0.4031 - accuracy: 0.8292\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 806us/step - loss: 0.4002 - accuracy: 0.8290\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 805us/step - loss: 0.3971 - accuracy: 0.8326\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 794us/step - loss: 0.3937 - accuracy: 0.8341\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 808us/step - loss: 0.3891 - accuracy: 0.8361\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 863us/step - loss: 0.3829 - accuracy: 0.8391\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 803us/step - loss: 0.3769 - accuracy: 0.8393\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 848us/step - loss: 0.3729 - accuracy: 0.8418\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 793us/step - loss: 0.3688 - accuracy: 0.8446\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 795us/step - loss: 0.3659 - accuracy: 0.8438\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 844us/step - loss: 0.3638 - accuracy: 0.8453\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 831us/step - loss: 0.3619 - accuracy: 0.8469\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8482\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 793us/step - loss: 0.3594 - accuracy: 0.8470\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 794us/step - loss: 0.3583 - accuracy: 0.8485\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3575 - accuracy: 0.8476\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 810us/step - loss: 0.3563 - accuracy: 0.8491\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 831us/step - loss: 0.3558 - accuracy: 0.8490\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 795us/step - loss: 0.3551 - accuracy: 0.8474\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 788us/step - loss: 0.3544 - accuracy: 0.8511\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 808us/step - loss: 0.3534 - accuracy: 0.8514\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 802us/step - loss: 0.3520 - accuracy: 0.8526\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 809us/step - loss: 0.3509 - accuracy: 0.8545\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 796us/step - loss: 0.3493 - accuracy: 0.8556\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 823us/step - loss: 0.3479 - accuracy: 0.8553\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3468 - accuracy: 0.8575\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 806us/step - loss: 0.3457 - accuracy: 0.8583\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 823us/step - loss: 0.3446 - accuracy: 0.8604\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 796us/step - loss: 0.3440 - accuracy: 0.8587\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 789us/step - loss: 0.3434 - accuracy: 0.8614\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 872us/step - loss: 0.3424 - accuracy: 0.8616\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 827us/step - loss: 0.3419 - accuracy: 0.8630\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 795us/step - loss: 0.3412 - accuracy: 0.8636\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.3406 - accuracy: 0.8636\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 826us/step - loss: 0.3402 - accuracy: 0.8600\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 802us/step - loss: 0.3398 - accuracy: 0.8633\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3395 - accuracy: 0.8636\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 836us/step - loss: 0.3393 - accuracy: 0.8618\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 791us/step - loss: 0.3391 - accuracy: 0.8630\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 796us/step - loss: 0.3383 - accuracy: 0.8639\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 788us/step - loss: 0.3380 - accuracy: 0.8625\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 798us/step - loss: 0.3375 - accuracy: 0.8634\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 798us/step - loss: 0.3373 - accuracy: 0.8637\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 791us/step - loss: 0.3373 - accuracy: 0.8639\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 810us/step - loss: 0.3366 - accuracy: 0.8622\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 793us/step - loss: 0.3365 - accuracy: 0.8645\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 804us/step - loss: 0.3363 - accuracy: 0.8630\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 855us/step - loss: 0.3360 - accuracy: 0.8636\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 802us/step - loss: 0.3357 - accuracy: 0.8645\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 803us/step - loss: 0.3354 - accuracy: 0.8650\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 803us/step - loss: 0.3356 - accuracy: 0.8646\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 799us/step - loss: 0.3351 - accuracy: 0.8631\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 800us/step - loss: 0.3351 - accuracy: 0.8646\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 787us/step - loss: 0.3353 - accuracy: 0.8641\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 802us/step - loss: 0.3349 - accuracy: 0.8652\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 860us/step - loss: 0.3345 - accuracy: 0.8621\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3349 - accuracy: 0.8644\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 810us/step - loss: 0.3343 - accuracy: 0.8666\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 795us/step - loss: 0.3344 - accuracy: 0.8649\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 809us/step - loss: 0.3341 - accuracy: 0.8640\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 804us/step - loss: 0.3342 - accuracy: 0.8649\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 796us/step - loss: 0.3342 - accuracy: 0.8662\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 799us/step - loss: 0.3340 - accuracy: 0.8652\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3338 - accuracy: 0.8645\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 794us/step - loss: 0.3336 - accuracy: 0.8670\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 803us/step - loss: 0.3340 - accuracy: 0.8664\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 795us/step - loss: 0.3336 - accuracy: 0.8655\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 838us/step - loss: 0.3332 - accuracy: 0.8658\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 791us/step - loss: 0.3332 - accuracy: 0.8652\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 807us/step - loss: 0.3337 - accuracy: 0.8649\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 821us/step - loss: 0.3333 - accuracy: 0.8649\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 810us/step - loss: 0.3329 - accuracy: 0.8658\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 797us/step - loss: 0.3333 - accuracy: 0.8658\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 810us/step - loss: 0.3334 - accuracy: 0.8660\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 802us/step - loss: 0.3331 - accuracy: 0.8666\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 804us/step - loss: 0.3330 - accuracy: 0.8658\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fe24e1a4940>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Here we store the model for later use during inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(ann, open('model.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Homework**\n",
        "\n",
        "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card ? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "During inference, we need to pay attention to the scaling of the input data. It needs to match the same scaling that we used on the training data. Hence the call to `sc.transform()`.\n",
        "\n",
        "Why not use `sc.fit()`? \n",
        "\n",
        "\"The fit(data) method is used to compute the mean and std dev for a given feature to be used further for scaling. The transform(data) method is used to perform scaling using mean and std dev calculated using the . fit() method. The fit_transform() method does both fits and transform\"\n",
        "\n",
        "See https://www.geeksforgeeks.org/what-is-the-difference-between-transform-and-fit_transform-in-sklearn-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "2d8IoCCkeWGL",
        "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[False]]\n"
          ]
        }
      ],
      "source": [
        "# load the previously saved scaler & model\n",
        "import pickle\n",
        "model = pickle.load(open(\"model.pkl\", 'rb'))\n",
        "scaler = pickle.load(open(\"scaler.pkl\", 'rb'))\n",
        "print(model.predict(scaler.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/63 [..............................] - ETA: 0s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 657us/step\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > .5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix\n",
        "\n",
        "See https://www.simplilearn.com/tutorials/machine-learning-tutorial/confusion-matrix-machine-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/4RDuRXhpZgAATU0AKgAAAAgABAE7AAIAAAAMAAAISodpAAQAAAABAAAIVpydAAEAAAAYAAAQzuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEVzaG5hIFZlcm1hAAAFkAMAAgAAABQAABCkkAQAAgAAABQAABC4kpEAAgAAAAMxMgAAkpIAAgAAAAMxMgAA6hwABwAACAwAAAiYAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjAyMDoxMjowNCAxOTo0OTo0NAAyMDIwOjEyOjA0IDE5OjQ5OjQ0AAAARQBzAGgAbgBhACAAVgBlAHIAbQBhAAAA/+ELHmh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjAtMTItMDRUMTk6NDk6NDQuMTIxPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPkVzaG5hIFZlcm1hPC9yZGY6bGk+PC9yZGY6U2VxPg0KCQkJPC9kYzpjcmVhdG9yPjwvcmRmOkRlc2NyaXB0aW9uPjwvcmRmOlJERj48L3g6eG1wbWV0YT4NCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgPD94cGFja2V0IGVuZD0ndyc/Pv/bAEMABwUFBgUEBwYFBggHBwgKEQsKCQkKFQ8QDBEYFRoZGBUYFxseJyEbHSUdFxgiLiIlKCkrLCsaIC8zLyoyJyorKv/bAEMBBwgICgkKFAsLFCocGBwqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKv/AABEIAOUBUQMBIgACEQEDEQH/xAAfAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgv/xAC1EAACAQMDAgQDBQUEBAAAAX0BAgMABBEFEiExQQYTUWEHInEUMoGRoQgjQrHBFVLR8CQzYnKCCQoWFxgZGiUmJygpKjQ1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4eLj5OXm5+jp6vHy8/T19vf4+fr/xAAfAQADAQEBAQEBAQEBAAAAAAAAAQIDBAUGBwgJCgv/xAC1EQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/APpGiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAo3mt6Vp0wi1DU7O1kIyEnuFQkeuCar/wDCVeHv+g9pn/gZH/jXFeJ7WC6+Id0LmFJQtlFgOucctVb+yNP/AOfKD/vgVz1sVToz5JJs66OEnWhzppHff8JV4e/6D2mf+Bkf+NH/AAlXh7/oPaZ/4GR/41wP9kaf/wA+UH/fAo/sjT/+fKD/AL4FZfX6P8r/AANv7PqfzI77/hKvD3/Qe0z/AMDI/wDGj/hKvD3/AEHtM/8AAyP/ABrgf7I0/wD58oP++BR/ZGn/APPlB/3wKPr9H+V/gH9n1P5kd9/wlXh7/oPaZ/4GR/40f8JV4e/6D2mf+Bkf+NcD/ZGn/wDPlB/3wKP7I0//AJ8oP++BR9fo/wAr/AP7PqfzI77/AISrw9/0HtM/8DI/8aP+Eq8Pf9B7TP8AwMj/AMa4H+yNP/58oP8AvgUf2Rp//PlB/wB8Cj6/R/lf4B/Z9T+ZHff8JV4e/wCg9pn/AIGR/wCNH/CVeHv+g9pn/gZH/jXA/wBkaf8A8+UH/fAo/sjT/wDnyg/74FH1+j/K/wAA/s+p/Mjvv+Eq8Pf9B7TP/AyP/Gj/AISrw9/0HtM/8DI/8a4H+yNP/wCfKD/vgUf2Rp//AD5Qf98Cj6/R/lf4B/Z9T+ZHff8ACVeHv+g9pn/gZH/jR/wlXh7/AKD2mf8AgZH/AI1wP9kaf/z5Qf8AfAo/sjT/APnyg/74FH1+j/K/wD+z6n8yO+/4Srw9/wBB7TP/AAMj/wAaP+Eq8Pf9B7TP/AyP/GuB/sjT/wDnyg/74FH9kaf/AM+UH/fAo+v0f5X+Af2fU/mR33/CVeHv+g9pn/gZH/jR/wAJV4e/6D2mf+Bkf+NcD/ZGn/8APlB/3wKP7I0//nyg/wC+BR9fo/yv8A/s+p/Mjvv+Eq8Pf9B7TP8AwMj/AMaP+Eq8Pf8AQe0z/wADI/8AGuB/sjT/APnyg/74FH9kaf8A8+UH/fAo+v0f5X+Af2fU/mR33/CVeHv+g9pn/gZH/jR/wlXh7/oPaZ/4GR/41wP9kaf/AM+UH/fAo/sjT/8Anyg/74FH1+j/ACv8A/s+p/Mj0O28Q6LeXCwWmr2E8znCxxXKMzfQA5NaNeTRWNra+KNAe3t44mN+ASigcbWr1muuE41IKcepxVabpTcGFFFFUZhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAec6/wD8lEvP+vKL+bU2na//AMlEvP8Aryi/m1Nrxsf/AB/kvyPdwH8Ber/MKKKK4TtCiiigAooooAKyNa8T6doF3Y2+oSFZL6Qxx4GcdOT6DJAz71r15/e6BrXiPVNavJbe3jhmjFlaJd71dEQ53qAO7HOf9kVpTim/e2M6kpJe7ud5PcwWsfmXMqRJnG52AFZ1/wCJNM03VrHT7u4VJr5XaEk8YXHU9s54rjrVNSk1LTtQ8TaVdXNvBZNaPEts0pSdWIMm0DJDrjDAdqtanpo/tzwpqFvos8Vja/aElhS3LNDv27MqucDIJ9s1appOzIdSTV0ux3H2mHy2k81NiHDNuGAff86a17bJcLA1xEJmGVjLjcfwrzLUbLUrXwz4m0VdLvp7m+1H7TbvDAzI0bGM/eAwCNh461Jr1tqN9p1/F/YckN7HNEbcw2TO0oXbiQygYB+8MZ6CmqS7idZ9jvbHXLe/1zUdLiRxNp4iMrEcHeGIx/3ya0q5Pw1Y3tv418RXd3byRxXMVp5cjLgOVV92D3wSPzrrKymknZGsG2rvzCiiioLCiiigAooooAKKKKAKz/8AIy+H/wDsIL/6A1eo15c//Iy+H/8AsIL/AOgNXqNe/hf93j8/zPAxn8d/IKKKK6DkCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA851//AJKJef8AXlF/NqbUXj+2DeL4RZw3r3k1oGc290IhtDEDr1rn/wCzdU/59tU/8Ga1z4jA+2nz86Wi3O/DYp06fKoN77HS0VzX9m6p/wA+2qf+DNaP7N1T/n21T/wZrXP/AGZ/08R0/Xpf8+5fcdLRXNf2bqn/AD7ap/4M1o/s3VP+fbVP/BmtH9mf9PEH16X/AD7l9x0tFc1/Zuqf8+2qf+DNaP7N1T/n21T/AMGa0f2Z/wBPEH16X/PuX3HS0VzX9m6p/wA+2qf+DNaP7N1T/n21T/wZrR/Zn/TxB9el/wA+5fcdLRXNf2bqn/Ptqn/gzWj+zdU/59tU/wDBmtH9mf8ATxB9el/z7l9x0tFY9rpkE3g/Udbnu9YiksJjC9v9szlht7/8CrGD3TKCIdWwRn/kIrQ8sa3mkEMc6nwU2/Q7GiuPzdf88dW/8GS0Zuv+eOrf+DJaX9nL/n5H7zT6zV/58y+47CiuPzdf88dW/wDBktGbr/njq3/gyWj+zl/z8j94fWav/PmX3HYUVx+br/njq3/gyWjN1/zx1b/wZLR/Zy/5+R+8PrNX/nzL7jsKK4/N1/zx1b/wZLRm6/546t/4Mlo/s5f8/I/eH1mr/wA+ZfcdhRXH5uv+eOrf+DJaM3X/ADx1b/wZLR/Zy/5+R+8PrNX/AJ8y+46d/wDkZfD/AP2EF/8AQGr1GvFvDrqvi/SPt1vqBzc4iM16JFV9pwSPzr2mu+nS9lTjC9/Q8rETlOq3KLXkwoooqjAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDgfFH/JQ7X/ALBv/tRqKPFH/JQ7X/sG/wDtRqKituvQ9TB/w/mFFFeWW3iK6uNN1yYa/cLq1tqNzFa2kZDbgshCL5eORisUrnTKaiep0VysPinUbieSytNOSa9sbaKS/DS7AkjIG8tfU4/mKhm8fQvZ6Tc2cKLFqKuRLdSeWkbIdpjLf3s5H4UWYc8TsKK5G+8QXK+I7ixg3LMNE+2KvmAxhtzj05PHWs7RvE+qS6D4Tm1Ri02pzBN8TAbxsJy4x7dBRYXtFex39FcqnjZHs4v9EIvnv2sWtt3KFeS2fTZhvxFU4/iPayeXdCKL7BJdG2VhMDL94rv2f3cj696LMftI9ztqKKKRZkxf8kt8Vf8AYQf/ANpVlxf6lP8AdFakX/JLfFX/AGEH/wDaVZcX+pT/AHRW+M+GP9dEZ5P8dT5fmx1FVdUne10e8uITiSKB3QkZwQpIrjLHxnft4NuX1HbFq0dkbmF9o2zL/eA6cHgivPUW9j251owdpHe0VzyeKCUWKC1e8uIbSO4utjBQm4ZHXqTg8U5PFUV5PBDpFrJfSywfaCAwQImcck985GPajlY/bQ7m/RWFp3iV9V0yW6stNlaSG6a2aF5FUgqBk5PGOaztZ8W3MfhO/vtPtjBe2VwkEsUhU7CXUH2IIbH40+V3sJ1oKPN8zrqK5pvEc8OqPDNbzeZFpjXjWqFWDYZRw3XPPTpU8vi+wjW3fDNFLaPdu4/5ZRqByfqSBS5WHtodWb1FYtn4jW4v7W1urSS1a8Qvbl2DbwBkg46HHOK2qTTRpGSkrodYf8jZoP8A1/D/ANBavZK8bsP+Rs0H/r+H/oLV7JXo0v4UfmfKZl/vUvkFFFFWeeFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBwPij/kodr/2Df8A2o1FJ4qYL8Q7XcQP+Jb3P/TRqTzY/wC+v51Fbdeh6eD/AIfzHVmaFoUGgwXUVtJJILm6lunL44aRixA9ua0fNj/vr+dHmx/31/OsNTs0vcw77wus+qXF/p+oXGnTXcYjufJVSJQBgE7gcHHGRQ3hWOPSIdM069ms7WKExGNVWQOCckkMDzkk5963PNj/AL6/nR5sf99fzp6k8sTAs/BlhZX0dzHLMfL01dNCMRjywWOfr8xqGy8EwWlvpMD6hcTRaRP51qrKg2jBAU4HI569a6XzY/76/nR5sf8AfX86NQ5YmGnhDT08Xy+IcubiSLYYicoGIAL4/vEKo+gpLHwqumsI7HUbmGyEzTC0ULtBJJIDY3YyScZrd82P++v50ebH/fX86NQ5YjqKb5sf99fzo82P++v50iroy4v+SW+Kv+wg/wD7SrLi/wBSn+6K1ISD8LPFJB4/tB//AGlWTE6+SnzL90d63xnwx/roiMn+Op8vzYy+the6fcWpbaJ4mjLemQRn9awdS8FWmp+E7bR5pWWS1jCRXS8OvGD+BHUV0m9P7y/nRvT+8v5156bWx7koQn8Rzcng6EXYubZ4hK9vHBL50CyBtgwGGeh5NR3ujTWeoW9xpy3Mcq2/kvcWyx/OM5AKEYHPOQK6jen95fzo3p/eX86fMyfZU+mhxek+DLoaNGt7OUnF/JeGKXEiPuG3DjofX2NXV8FRnRdUsHucf2hMsxaOMIIypBGAO2VFdPvT+8v50b0/vL+dPmkSqFJKxjWegvDryarc3IlmWyNoyhMKRuDZ/wDHaqWPgmytbfVIJZHmiv1MYVv+WMfJ2r+JJ/Kuk3p/eX86N6f3l/OleRfs6fYxNK8Of2bcxSGSFlhUqmy2RWbjGSwGc/TFblJvT+8v50b0/vL+dJ3ZcYxgrIfYf8jZoP8A1/D/ANBavZK8a09gfFug4IP+nDof9lq9lr0af8KPzPlcy/3qXyCiiiqPPCiiigAqlrV7Jp2gahfQhWktrWSZA3QlVJGfyq7WT4q/5E3Wv+vCf/0W1VHWSE9jirbxP4uubWOdbrTVEihgDbtxn8ak/wCEg8X/APP5pv8A4Dt/jVPS/wDkE2v/AFyX+VW68eeOrKTSt9yPbjgaLim0/vYv/CQeL/8An803/wAB2/xq1ofibX5PFdlp2qyWcsF0khzDEVKlVJ7n2qpUemf8lC0X/cn/APRZrfC4urVq8krW16LsY4nCUqVJyjvp1fcli8T+Kb+S5ktLjT4YUuJIkR4GYgKxHJz7VL/bXjD/AJ/dM/8AAZv8aoaF/wAet1/1+z/+jDWnXfUqyjNxSX3GdHC0504ye7Xcj/trxh/z+6Z/4DN/jR/bXjD/AJ/dM/8AAZv8akoqPby8vuRr9Tpef3sj/trxh/z+6Z/4DN/jR/bXjD/n90z/AMBm/wAakoo9vLy+5B9Tpef3sj/trxh/z+6Z/wCAzf41Fc+IfF9rayztd6awjUsQLducfjVmqmrf8ge7/wCuTfypxrSbSsvuJlhKSi3r97F1cSeKbzRo/wCx9Nu7ufS47t5LosAu7qowemai/wCECvf+hd8P/wDfcv8AjWl4a/5GDQP+xchru67ZVJU/dieLGClqzzL/AIQK9/6F3w//AN9y/wCNH/CBXv8A0Lvh/wD77l/xr02io+sTK9lE8y/4QK9/6F3w/wD99y/40f8ACBXv/Qu+H/8AvuX/ABr02ij6xMPZRPMv+ECvf+hd8P8A/fcv+NH/AAgV7/0Lvh//AL7l/wAa9Noo+sTD2UTzL/hAr3/oXfD/AP33L/jR/wAIFe/9C74f/wC+5f8AGvTaKPrEw9lE8y/4QK9/6F3w/wD99y/40f8ACBXv/Qu+H/8AvuX/ABr02ij6xMPZRPOLS5XSNA8Q6TqOiWKw2KRStb2rNsmMpI5LZ/uiq6eEXkjV18B6fhgCP9Oqx4h/4+/Gf/XvY/8AobV6Fa/8ecP/AFzX+VXKbgrrr69kTGN3Y83/AOEOk/6EPTv/AAOo/wCEOk/6EPTv/A6vTaKj28v6v/mX7Nf1Y8y/4Q6T/oQ9O/8AA6j/AIQ6T/oQ9O/8Dq9Noo9vL+r/AOYezX9WPMv+EOk/6EPTv/A6j/hDpP8AoQ9O/wDA6vTaKPby/q/+YezX9WPMv+EOk/6EPTv/AAOo/wCEOk/6EPTv/A6vTaKPby/q/wDmHs1/VjzL/hDpP+hD07/wOo/4Q6T/AKEPTv8AwOr02ij28v6v/mHs1/VjzS20xPD2r6dd3Hg6zs/Mu4oEniu97Rs7BQcfjXpdc34z/wCPfSP+wvaf+jlrpKmpLmSkxxVm0FFFFYlhRRRQAVk+Kv8AkTda/wCvCf8A9FtWtWT4q/5E3Wv+vCf/ANFtVQ+JClszgtL/AOQTa/8AXJf5Vbqppf8AyCbX/rkv8qxJvF1xFqo08aDevcMhkCqyH5QcbuvAr5ucXKcrH08ZKMFc6ao9M/5KFov+5P8A+izVDQdaTXbBrlLeS2KSNE8UpG5WU4IOKv6Z/wAlC0X/AHJ//RZrpwSaxCT8/wAmc2MaeHbXl+ZFoX/Hrdf9fs//AKMNadZmhf8AHrdf9fs//ow1lXvii8i1fWLW2t7Yx6UiO3nSFTLuQPwe3pXqVv4kvUyoSSoxv2OoorCi8YaW9jbTyu8bT2yXJi2FmiRhnLAdBVlPEely3EEMFyJmnjWVDGCw2N91iR0BrI25l3NSiuXm8bQQana2nkNcfaLue2324LeWYiQcjHJ4rRh8RWbahLaTTRq4uvs0YXPL7Q2D6Hmiwc0Wa9VNW/5A93/1yb+VU/8AhKdJMjRpcGSQSPHsRCzEocNgdwD3qW5vbfUfDc91ZSrNBJAxR1PB4qo/EiZNOLsavhr/AJGDQP8AsXIa7uuE8Nf8jBoH/YuQ13dd1b4j5+nsFFFFYmhDdQyT2rxwXD20jDiWNVLL9AwI/MV5lp3jTV9H0q51PVru81s/23JpUFokcEWfmIViVQHIx616nXPDwVpAtlg8uTYupHUx+8P+uyTn6cnigCh/wnwi0/xFPeaY8M2gOiTwiYNvLRpJw2P+mgH4VW1H4o6fZX15bx23nGwijkuczBGBdQ+1Vx8xCkHt1rQ1j4faPrN1qEs73UK6mE+2xQTsizlQArEeoAA464Gc1PN4K01tQe8tZbqzlmRI7j7PMVEwQYXPoQOMjBx3oA3LO6ivrGC7tyTFcRrKhIxlWGR+hqakRQiKi5wowMnNLQAUUUUAeceIf+Pvxn/172P/AKG1ehWv/HnD/wBc1/lXnviH/j78Z/8AXvY/+htXoVr/AMecP/XNf5V0VfhX9dEZQ3f9dWS0UUVzmoVwHhTxvqPiKKOabUNFgZp5ENmsUhm2oxGM78ZIGeld/XPaL4Rt9H8KyaIszusgmBnUBXXzCxJBHQjdwaAKt945tFsNXWzimi1Cx06a9ihuotokWNeo55GdoP1qTSfGtte/2faTRTSahc2sVxKtvEWSISDgk54GQfyrGsvhcltcTu+oLtk0efSVEVskZ2SlT5jEcs/y9+PYc50Z/AYm/slVvyi6aIgkqwqJsRnOBIBkK2MMDkEelAFtPHmhyXccSyy+XJc/ZEuTH+6aX+6G+ox9eK6SuJ034bWel3qiBrZ7JLk3KRy2cbyK2d2A5HQHkfxD1rtqACiiigDm/Gf/AB76R/2F7T/0ctdJXN+M/wDj30j/ALC9p/6OWukrSXwL5kr4mFFFFZlBRRRQAVk+Kv8AkTda/wCvCf8A9FtWtWT4q/5E3Wv+vCf/ANFtVQ+JClszgtL/AOQTa/8AXJf5VzXimaLRtdg1W21SCyvpYfIaKeFpUkTcMHapBGD3zXS6X/yCbX/rkv8AKuR8WaY2r6zPDpF/arfNaqk8FxnGwOCCCDwcjpXzyt7V38z6SV/ZKxueE7S3ttOuHgvRezT3MklzMBtBlz8wx2x0xWzpn/JQtF/3J/8A0Waw/CMUcNnej7Wl1ctdyNctEu1FkJ5UD0Fbmmf8lC0X/cn/APRZrown+8/f+TOfFf7s/l+ZFoX/AB63X/X7P/6MNUl8I2MniPU9U1CKC8F75W2OWIN5exAvfrnGau6F/wAet1/1+z/+jDWnXpVv4kvUigk6ML9kc9P4evINbvdQ0a8gtzfRLHNHNCXClRtDLgjHHbpVKHwO1lb6bb6deLAtksa/aAhEzhTlgSCFIPPBBAzXXUVndmvJE5GPwXcW17Dd2t9H50OpXN6okiJUiYklSAQcgHrUl14MNxZ6tGt75c95eC8t5gnNvIAMH35FdVRRdhyROOPgMWzadNp95sntbU28pkLgTZJYsdjKcliT171sR6amkeEprOMINkTs3lghSzZJIySepPUmtmqmrf8AIHu/+uTfyqov3kTKKUW0XvDX/IwaB/2LkNd3XCeGv+Rg0D/sXIa7uu2t8R4FPYK8+8X3Dn4k6RZyLqdxavp87tbafO8ZZgwwx2svSvQarvY2smoR3zwIbqJDGkpHzKp6jPpxWJocDpOr+JNIOl+HrkQpe3zXM8UuoO0nkW6v8iMQQXfaw78e9L/wsDWXspWSxtV+w38tpfXao0sahFVg6oGBwQ+DydpB613Go6Rp+rpGupWkdx5Tbo2YfNGfVT1B+lV38MaI9lFaHTLYQRbtiKm0Dd97p69/XvQB5x4r8WalJJqp0S5igaH+zmW6V5GWRJSScLu2gHjkAEjrnjG7rHiTV9M8Tahb2ttb3d3Z6LBeMVaUJJmaUOAm/A+VMg9fUkYFdZN4b0a4jnSXTbdkuI0jlXYAGVPuD8O3pU0Oj2FvcefFaxibyFtzIRljGCSFJPUZY/nQBwM/xRuriZZ9Hs4ZtNurqGztLlkZt0hjMkjEAjIAKqAMHIbmus8La3qGrrfJqlibd7Wfy45ghRJ1Kg7gpJI5JBBJ6e9XB4b0ZdIXS10y2Firl1gEYCqxJO4DscknIqzYabZ6XAYbC3SFGYu23qzHuT1J9zQBaooooA848Q/8ffjP/r3sf/Q2r0K1/wCPOH/rmv8AKvPfEP8Ax9+M/wDr3sf/AENq9Ctf+POH/rmv8q6Kvwr+uiMobv8ArqyWoL2RobC4ljOGSJmU+4FT0yWNZoXikGVdSrD2Nc5qeWeHfFmt3lj4fvINXudVnupW/tG2e2jWKCEB8vuVAQQQuOTnNdHF8Qt1nZapLpEsejXtyttFeecC2WbarGPHCluM57ium0nSbXRtHg0yyQi2gUoisc8ZJ/rWND4C0WCSEKLhrS3n+0Q2TTsYY5M53Bc+pyAeAeQKAMyb4gefoOuXQtJLM6dE52rOvnjDYyUZSF9RncKq2PjTWJZ/FhurcfYdJtFmimSVRKv7ln6FcEnHfgehrfuPAmkXcl2959ouGurZrUtJMzFImYMVB69VB5yeKefBel+fqDoZ0TUrX7LdRLJ8si7SgPsdpIyKAMcfEa3tNPn+1WszXEVjBdWyvIu68MpCBRgAA7yoOB/EKjPxVsRJKxsm8i3ultZmEwMiuSqkhMfMoLcnI6Hit248E6JdXWjXE9sXk0UYtCXPAxjDf3hwDz3ANKng7TodTlu7WS6tlnn+0TQQzssckn94jt05AwD3BoA3lYMoYdCMiloooA5vxn/x76R/2F7T/wBHLXSVzfjP/j30j/sL2n/o5a6StJfAvmSviYUUUVmUFFFFABWT4q/5E3Wv+vCf/wBFtWtWT4q/5E3Wv+vCf/0W1VD4kKWzOC0v/kE2v/XJf5VzMuh+H7jx3LbPpCyXMlr5887SsB97AAXuSe9dNpf/ACCbX/rkv8q57XbeXULiOb+xL4XEe5FuLW5EbBc9M55B64NfO/8ALyXzPpLe5Ev+Fbmylsrq3sLBLEWl1JBJEhyCwP3s989a2dM/5KFov+5P/wCizWd4ctktNJWGLTpNPAYkxyyb2YnqxbJyT71o6Z/yULRf9yf/ANFmunB/7z9/5Mwxd/qzv5fmRaF/x63X/X7P/wCjDWnWa+imwu7qK28ZaZAjTySeVLb7mQsxJBO8etJ9in/6HjSP/AX/AO2V7VSg5Tck9/X/ACOCljKcKai09PT/ADNOisz7FP8A9DxpH/gL/wDbKPsU/wD0PGkf+Av/ANsrP6tLv+f+Rp9ep9n+H+Zp0VmfYp/+h40j/wABf/tlH2Kf/oeNI/8AAX/7ZR9Wl3/P/IPr1Ps/w/zNOqmrf8ge7/65N/Kq/wBin/6HjSP/AAF/+2UyfTJbiB4ZPHGk7ZFKnFr2P/bSqjh5Jp3/AD/yFLHU3Fqz/D/M2fDX/IwaB/2LkNd3XFzeH7q1k0q60rX7O0e202Oz3Tw7xKo/iHzDGfxqTy/En/Q3aR/4B/8A2yt5pTd0/wAzyotxVrHYUVx/l+JP+hu0j/wD/wDtlHl+JP8AobtI/wDAP/7ZUez8/wA/8iubyOworj/L8Sf9DdpH/gH/APbKPL8Sf9DdpH/gH/8AbKPZ+f5/5BzeR2FFcf5fiT/obtI/8A//ALZR5fiT/obtI/8AAP8A+2Uez8/z/wAg5vI7CiuP8vxJ/wBDdpH/AIB//bKPL8Sf9DdpH/gH/wDbKPZ+f5/5BzeR2FFcf5fiT/obtI/8A/8A7ZR5fiT/AKG7SP8AwD/+2Uez8/z/AMg5vIyPEP8Ax9+M/wDr3sf/AENq9Ctf+POH/rmv8q41PC1zeWOutf69a3E+pRwoZoYdqQ+WSRkbjnOfUVKkPiOONUXxdpGFAA/0P/7ZWk0pKye3r2REbp3sdlRXH+X4k/6G7SP/AAD/APtlHl+JP+hu0j/wD/8AtlZ+z8/z/wAi+byOworj/L8Sf9DdpH/gH/8AbKPL8Sf9DdpH/gH/APbKPZ+f5/5BzeR2FFcf5fiT/obtI/8AAP8A+2UeX4k/6G7SP/AP/wC2Uez8/wA/8g5vI7CiuP8AL8Sf9DdpH/gH/wDbKPL8Sf8AQ3aR/wCAf/2yj2fn+f8AkHN5HYUVx/l+JP8AobtI/wDAP/7ZR5fiT/obtI/8A/8A7ZR7Pz/P/IObyLnjP/j30j/sL2n/AKOWukrin0nV9TvLEal4o064ht7uK48qG12s5RwwAPmHrj0rtaJ2UUrhHVthRRRWRYUUUUAFZPir/kTda/68J/8A0W1a1ZPir/kTda/68J//AEW1VD4kKWzOC0v/AJBNr/1yX+VcTqmkaVY+Mo01OW+tdOktmdX/ALQuAkku7kE7+MDoBiu20v8A5BNr/wBcl/lXHePdbvLG68iO7WygjhWZWaNW89t4BXLAgAD8a+fV/atLzPo5W9km/I1PAYddGuQDO9sLuQW0txI7vJHu+UncSa6TTP8AkoWi/wC5P/6LNY/hXUZ9SsLmSaQTRpdSRwTBdvmRg8HH6Z71saZ/yULRf9yf/wBFmt8J/vP3/kzDFf7rp5fmcvDZWs1xevNbQyObybLNGCfvmpf7Nsf+fO3/AO/S/wCFLa/629/6/Jv/AEM1YrsxE5KrLXqeng6cHhqbaWyK39m2P/Pnb/8Afpf8KP7Nsf8Anzt/+/S/4VZorD2k+51+yp/yr7it/Ztj/wA+dv8A9+l/wo/s2x/587f/AL9L/hVmij2k+4eyp/yr7it/Ztj/AM+dv/36X/CoL7T7JbCcraQAhCQREvHH0rQqvf8A/IPuP+uZ/lVwnPmWpnUpU+R+6tjqNL0uy1bWPD0GpWyXMS+HoWCSDIB9a6n/AIQnw1/0BrX/AL5rB8Nf8jBoH/YuQ13devVnJOyZ8LCKa1Rhf8IT4a/6A1r/AN80f8IT4a/6A1r/AN81u0Vl7Sfdl8sexhf8IT4a/wCgNa/980f8IT4a/wCgNa/981pahqtjpUaSajdR26yNsQucbj6D1pbHUrTUomksZ1mRTtJXPBo9pPuw5Y9jM/4Qnw1/0BrX/vmj/hCfDX/QGtf++a1WvrVNQSxadBdSRmRYs/MVBwT9KsUe0n3Ycsexhf8ACE+Gv+gNa/8AfNH/AAhPhr/oDWv/AHzW7RR7Sfdhyx7GF/whPhr/AKA1r/3zR/whPhr/AKA1r/3zW7RR7Sfdhyx7Hl+p6fa6aPGVpYQLBb/Z7M+WnA5ds111v4K8NtaxM2j2pJQEnb7VzXiH/j78Z/8AXvY/+htXoVr/AMecP/XNf5VvUlJRVn/VkZxir/13Zj/8IT4a/wCgNa/980f8IT4a/wCgNa/981u0Vh7SfdmnLHsYX/CE+Gv+gNa/980f8IT4a/6A1r/3zW7RR7Sfdhyx7GF/whPhr/oDWv8A3zR/whPhr/oDWv8A3zW7RR7Sfdhyx7GF/wAIT4a/6A1r/wB80f8ACE+Gv+gNa/8AfNbtFHtJ92HLHsYX/CE+Gv8AoDWv/fNH/CE+Gv8AoDWv/fNbtFHtJ92HLHscP4k8N6PpTaPc6dp8NvMNWtV3xjBwZVyK7iub8Z/8e+kf9he0/wDRy10lVJtxTYopJuwUUUVkWFFFFABWT4q/5E3Wv+vCf/0W1a1ZPir/AJE3Wv8Arwn/APRbVUPiQpbM4LS/+QTa/wDXJf5VzmvwX9x4ng+xQaXqVv5JWaxvroLk5yGVdjYPv+ldHpf/ACCbX/rkv8q8zlDW9g0raXenW01cXBuFtySY/OBPzf3dmeOlfPpXqS9T6KTtCKPS9LN19iAvbGCxdTgQ283mKB252r+WKsaZ/wAlC0X/AHJ//RZqDTtQj1K1E8Uc0YzjbNGUb8jU+mf8lC0X/cn/APRZrXBf7wvn+TM8Z/u7+X5o5hbmG0S/nupViiS8mLO5wB+8NWWuYUMQaVAZjiPn7568VzXi+3e68J6zDHG0pa8lGxRkkeaayb+x1XS9Z0rT7WF7m0inaW0mY58r5D+7b2B6H0rurxTqy9WduGqyhQgracsfxO/orz6yvNfmsYmt5mj1EW7m4S4ZiGk28ZGwKuG9Dj606y1G5j8R6VHbSajKGtZZLmGYjDuE/nn049Kx5DpWJTtod8zKilnIVQMkk4Apn2iHMX7xT5v+rwfvcZ4rz+C41HUPtNvmd47zTXeSAq/7uXsu44+btxge1XdNSUWXhiCya4WNo3W53bsqwiHB3dMGjksCxHM9F/Vzt6r3/wDyD7j/AK5n+VcO1z4mk0+5WETC40mBoNxH/Hy+cbx6/Jgj3NaWmT3U73ZWZjZ/Zfmjdnch+fm3Mi4z3H8qqMbSRMq6lFq3Q9Z8Nf8AIwaB/wBi5DXd1wnhr/kYNA/7FyGu7r1a3xHxVPYKKKw9O8Y6Hqtvqc1jerINKlkhu1wQ0TISG4/A81iaGN4/tL661fwr/ZoUSR6luMkkJkRBsPLAEcfiKpeMbvVrNLSwupwnmxzSm+s4JI41ZQNqbFZmLHnHzAexruLLUrXUNPtL22mUwXkSzQljgurAEHB9jU7zRRsFeRFYjIBYA0AeU6bLrGpahoOpXsk9vdv4cnWS7+zklJN4wSvrxnFRNrXiCHw9FDapeSQ2+oxxX12JWImiMeSyExl0BY/MMNg9D6etmaNXVGkQM33VLDJqhH4h0ye41C3t7pZZ9ObbcxJyyHaGxjvwwPHrQBjeBZtQnt9Qe7uPOs/tH+hqzMzRLtGVLsqlhnJBx36murqKK5imt1mVgFKhvm4K5GefTrTvNjLhBIu4jIXdyRQA+iiigDzjxD/x9+M/+vex/wDQ2r0K1/484f8Armv8q898Q/8AH34z/wCvex/9DavQrX/jzh/65r/Kuir8K/rojKG7/rqyWiio5Z4bfZ58qRb2CLvYDc3oM9T7VzmpJXC/FO0j/wCEft7xHnin/tCzh3xXDp8jToGGFIHIJFduZohOITIglZSwj3DcQOpx6cj86Zd2dtfQiK8hSaMOrhXGQGU5B+oIBoA83vPFOv6ReeKYdIhsY9L8Owo6CdJJZZmdScbi/AGM554/OtDVviHNpuqPDFDBdxReHpdVdIj85kVowoznhTvbt2rtf7Nst1032WIm7AFxlAfNAGMN68Eiqdr4d0PS5GnttOtbdmjMLSbAMoSPkye2QOKAMHw14o1rUtXtIL60iltLu0M/2iGPy/JYbcKQXbcCCfmGOR05rs6zbDSdH0y7YafbW1vcMn3UADbM9h2GcdOK0qACiiigDm/Gf/HvpH/YXtP/AEctdJXN+M/+PfSP+wvaf+jlrpK0l8C+ZK+JhRRRWZQUUUUAFZPir/kTda/68J//AEW1a1ZPir/kTda/68J//RbVUPiQpbM4LS/+QTa/9cl/lVuqml/8gm1/65L/ACq3XzNT436n1FP4EFR6Z/yULRf9yf8A9FmpKj0z/koWi/7k/wD6LNdWB/jr0f5M5sd/Afy/M521/wBbe/8AX5N/6GasVXtf9be/9fk3/oZqxXZiP40vU9TBf7tT9F+QjKrqVcBlIwQR1qvbabZ2chktraONyMFgOcen0qzRWJ1WT1CiiikMKr3/APyD7j/rmf5VYqvf/wDIPuP+uZ/lVw+JGdT4H6HZ+Gv+Rg0D/sXIa7uuE8Nf8jBoH/YuQ13dexW+I+Cp7BXkDeANct/DOrX+jwLb67Je3/7l2G28t5J5GVWweDhgVPbNev0ViaHjVp4S8T21uLbULWaaGXSrOCAwxiRrNkhVHQEyoFO8M24A5z7Vn+J7G90/SfEGnXoOsapcNCbS8M7JNGPLjXZsA65DH5cg7jkivdaY0MTSCRo0Lr0YqMj8aAPJ/FWi+Kb2Sb7Np1yZoPsosJrQxjIAXzDIzHIIO4YXtjrV6fwxqEOp+PPs2kv52rYlsbuPaAR5EaFM5yDuUnpj3r02igDy++8J+ITfafaWauNO1e0to9XYy/NbNCPmI55Ljapx/dqva+FvEKahPa3sdwJP7UNxDqMEYbEWcqN5lBAC/KV2EfWvWKKACiiigDzjxD/x9+M/+vex/wDQ2r0K1/484f8Armv8q898Q/8AH34z/wCvex/9DavQrX/jzh/65r/Kuir8K/rojKG7/rqyWuB+LGkjW7Hw3YMZkSXXI90kBIaP9xNhgR0wcGu+pCqtjcAcHIyOhrnNTw/UtX8V6Z42nRrGWfVtJ8P3Ecd1szHco1xbgSjH8QUMSvqvvWvN4h8WJazy6Zfpe2ht4TM6t51xbkyKHdFEaqfkLHackEDg9K9ZKKW3FRuxjOOcVXuNNtLq0ktZoF8mX76r8ufxGDQB5fD4wvbTXvEUVvqWqatp9ppsEsQeBY5UkeTaSDsHHfJU4APXFZmr6xrGs+FPFdjcXk8senz6bNDNDIJGCvODIN4jUEKFzwvHcnpXremaDpmkecdPtRG0+PNdnZ2fHQFmJJAyeKurbworKkMaqwwQFABFAHnd3cazceIbqy0C/eRl8P8An2l08aEyTCVSAX29DjBHvnFZNx4y8U6jpq63YCa006e9gsWR49rQKoYyzZKnGX2oDggAk164sUaY2Iq4GBgYwPSjy02FNi7T1XHBoA5jwVe6reHUv7Ru4bu1SZfskqSb3AI+ZWOxQcHGCPWuppqRpEgWNFRR0CjAp1AHN+M/+PfSP+wvaf8Ao5a6Sub8Z/8AHvpH/YXtP/Ry10laS+BfMlfEwooorMoKKKKACsrxSpfwfrKoCzGwnAAHJPltWrRTTs7ieqseN6f4g02HTreOS4ZXWNQw8p+Dj6VY/wCEk0r/AJ+T/wB+n/wr1yiuOWDoSbev3r/I71jqyVtPuf8AmeR/8JJpX/Pyf+/T/wCFT+HtQttR+IOkmzdpBHHNvPlsAuYz6ivVaK0pYalSlzxvf1/4BnVxdWrDkla39eZ4RHqNnbXV9HPcxxuLybKs2CPnNS/2xp3/AD+w/wDfYr3KirnShOTk76/12OqjmVSlTjTSWiseG/2xp3/P7D/32KP7Y07/AJ/Yf++xXuVFT7Cn5/18jX+16v8AKjw3+2NO/wCf2H/vsUf2xp3/AD+w/wDfYr3Kij2FPz/r5B/a9X+VHhv9sad/z+w/99ioL3VtPexmVbyEsUIADdeK95opqjBO+v8AXyJlmtWSa5UedaTqVlpeteHpdRuY7aNvDsKhpW2gn0rq/wDhMPDv/Qas/wDv6K2qK6pTjJ3a/r7jxVFoxf8AhMPDv/Qas/8Av6KP+Ew8O/8AQas/+/oraoqbx7fj/wAAfvGL/wAJh4d/6DVn/wB/RR/wmHh3/oNWf/f0VtUUXj2/H/gB7xi/8Jh4d/6DVn/39FH/AAmHh3/oNWf/AH9FbVFF49vx/wCAHvGL/wAJh4d/6DVn/wB/RR/wmHh3/oNWf/f0VtUUXj2/H/gB7xi/8Jh4d/6DVn/39FH/AAmHh3/oNWf/AH9FbVFF49vx/wCAHvHmGrX9pf8A/CZ3NlcRzwfZ7L95G2Rw7Z5rsbbxf4eW1iB1mzBCAEeaPSt6irlUjJWa/qy8vISi11MX/hMPDv8A0GrP/v6KP+Ew8O/9Bqz/AO/oraoqLx7fj/wB+8Yv/CYeHf8AoNWf/f0Uf8Jh4d/6DVn/AN/RW1RRePb8f+AHvGL/AMJh4d/6DVn/AN/RR/wmHh3/AKDVn/39FbVFF49vx/4Ae8Yv/CYeHf8AoNWf/f0Uf8Jh4d/6DVn/AN/RW1RRePb8f+AHvGL/AMJh4d/6DVn/AN/RR/wmHh3/AKDVn/39FbVFF49vx/4Ae8cT4m8Q6RqR0e3sNRt7iY6taEJHICcCVa7aiiiUk0kgSad2FFFFQUFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//Z",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "Image(\"https://www.simplilearn.com/ice9/free_resources_article_thumb/confusion-matrix.JPG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1507   88]\n",
            " [ 195  210]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8585"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "artificial_neural_network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
